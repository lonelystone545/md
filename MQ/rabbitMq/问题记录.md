[TOC]
# 为什么使用MQ
1. 系统间解耦：A系统只需要把消息丢在MQ中，关心该消息的系统自动去订阅这个消息即可，A系统不关心下游是谁。。如果采用http或者dubbo，那么每次A系统都需要开发，对接新的B、C、D系统；
2. 异步处理：将非核心流程的同步业务进行异步化，可以减少请求处理时间；
3. 削峰填谷：在高并发时，下游系统无法承受那么高的并发压力。通过MQ中间件做了一层缓冲，下游系统只需按照自身的处理能力消费消息即可。数据库能力有限，不能像业务服务器一样扩容很多台机器。

缺点：
1. 系统可用性降低，引入新的中间件MQ，如果MQ挂了呢！
2. 系统复杂性变高，需要考虑消息重复消费/可靠性/一致性等问题；

#prefetchCount作用
prefetch允许为每个consumer指定最大的unacked messages数目。简单来说就是用来指定一个consumer一次可以从Rabbit中获取多少条message并缓存在client中(RabbitMQ提供的各种语言的client library)。一旦缓冲区满了，Rabbit将会停止投递新的message到该consumer中直到它发出ack。

假设prefetch值设为10，共有两个consumer。意味着每个consumer每次会从queue中预抓取 10 条消息到本地缓存着等待消费。同时该channel的unacked数变为20。而Rabbit投递的顺序是，先为consumer1投递满10个message，再往consumer2投递10个message。如果这时有新message需要投递，先判断channel的unacked数是否等于20，如果是则不会将消息投递到consumer中，message继续呆在queue中。之后其中consumer对一条消息进行ack，unacked此时等于19，Rabbit就判断哪个consumer的unacked少于10，就投递到哪个consumer中。

总的来说，consumer负责不断处理消息，不断ack，然后只要unacked数少于prefetch * consumer数目，broker就不断将消息投递过去。

# 消息堆积如何解决？
原因：
1. 生产者生产消息速递大于消费者消费速度。
2. 消费者实例IO阻塞或者挂机，故障一段时间。
3. 消费者代码bug，忘记回复ack。
影响：
1. 消息堆积过多，会触发流控机制，从而阻塞生产者连接，生产者无法继续发送消息，影响业务。
目标：尽快将堆积的消息消费完毕。
解决方案：
1. 增加消费者的数量
2. 每个消费者增大prefetchCount，即MQ每次推送给消费者的最大消息数，监控板上有consumer utilisation表示消费者利用率，如果为100%，表明MQ拿到消息后可以立即发送给消费者，不需要等待消费者；通过提高prefetchCount可以提升该指标，但是如果prefetchCount过大，那么性能瓶颈出现在网络上，效果提升不明显。
    (prefetchCount选取参考[排队理论](https://www.rabbitmq.com/blog/2012/05/11/some-queuing-theory-throughput-latency-and-bandwidth/)，即如果客户端到mq的网络时延为50ms，客户端处理一条消息仅5ms，如果每次只获取一条数据，那么一共需要过105ms才能处理下一条数据，而这105ms期间，只有5ms的客户端处理时间，其他均空闲。但是如果每次获取100/5=20条数据，那么客户端在处理第一条数据后，回复ack，到发送下一条消息，需要100ms，此时客户端能够不停的处理消息。但是如果prefetchCount过大，且可能消息一直在客户端的内存队列中排队，较大的延时，如果有多个消费者，则分配不均匀，有些消费者很忙，有些很闲。还需要考虑优雅停机的时间是否足够处理完这些消息，否则会丢失。因素：网络传输时间/处理一条消息耗时/网络状况/停机的时间)
3. 每个消费者可以开启并发模式消费消息，默认concurrentConsumers=1.
4. 对于消费者代码的bug，异常未回复ack，此时需要修改完代码后，将消费者重启即可。因为MQ broker发现消费的连接断开了，会将没有收到ack的消息重新发送给其他消费者。这也是MQ判断是否重新发送的唯一依据。
5. 对于kafka堆积：写一个临时分发数据的程序，去消费积压的数据，不做任何业务逻辑处理，然后将数据分发到一个新的topic中，这个新topic有更多的partition，意味着我们可以增加更多的消费者来消费。
6. 如果还是消费太慢，消费者不做任何业务处理，直接丢弃数据或者保存数据库中，再处理业务；或者直接从源头重新发送MQ消息(如果消息可以重新获取或者生产者保存了MQ消息记录)；即便是TTL过期的消息也能够找到消息重发！

# 心跳
保证服务端和客户端的心跳小于LVS的心跳，否则空闲连接会被LVS杀死。
rabbitmq在收到来自客户端的connection.tune-ok信令后，启用心跳检测，rabbitmq会为每个tcp连接创建两个进程用于心跳检测，一个进程定时检测tcp连接上是否有数据发送（这里的发送是指rabbitmq发送数据给客户端），如果一段时间内没有数据发送给客户端，则发送一个心跳包给客户端，然后循环进行下一次检测；另一个进程定时检测tcp连接上是否有数据的接收，如果一段时间内没有收到任何数据，则判定为心跳超时，最终会关闭tcp连接。另外，rabbitmq的流量控制机制可能会暂停heartbeat检测。
心跳包每半个超时时间发送一次。 丢失了两个心跳包， 连接被认为不可抵达。 不同的客户端有不同的提示， 但tcp连接都会被关闭。 当客户端检测到RMQ节点不可抵达（根据心跳判定）， 它需要重新连接（到服务器）。

# 如何保证消息不丢失？或者消息的可靠性投递？
[可靠性分析](https://www.jianshu.com/p/ea04ee9504c3)
持久化，将队列设置为持久化，那么队列中的消息将全部进行持久化；或者针对消息级别进行持久化。持久化无法解决意外停机问题，即如果mq broker收到生产者消息后还没来得及进行持久化就断电了，如何处理？此时需要用到事务或者确认模式。
1. 生产者-->broker
    事务或者confirm + mandatory
    1. 事务，不推荐，性能太差。这里的事务不是分布式事务，是为了保证消息顺利到达broker。事务机制需要等待上一条消息执行完后再发送下一条消息。如果MQ本身异常，就调用回滚。通过txSelect开启事务之后，我们便可以发布消息给broker代理服务器了，如果txCommit提交成功了，则消息一定到达了broker了，如果在txCommit执行之前broker异常崩溃或者由于其他原因抛出异常，这个时候我们便可以捕获异常通过txRollback回滚事务了
    2. confirm：设置channel为confirm模式后，channel中的每个消息都会有全局id，成功投递到queue后，会给生产者回复ack，否则nack。支持单条同步/批量同步/异步回调。但是confirm无法解决消息根本没有到达exchange的情况(网络丢包，故障)。因此需要在生产者端维护一个请求记录表，记录每个消息的状态，决定是否进行重试。
    3. mandatory：true表示如果消息找不到对应的队列，则返回给生产者决策；false则直接丢弃，忽略。或者在声明exchange时添加alternate-exchange，这样如果消息找不到队列，则会发送到alternate-exchange中。
2. broker-->消费者
    为了保证消息从队列可靠到达消费者，mq提供了消息确认机制。当autoAck=false时，rabbitmq会等待消费者显示回复ack信号后才从内存或者磁盘中删除消息，当为true时，那么rabbitMQ会在队列中消息被消费后立刻被删除，此时无法知道消费者有没有收到该消息。消费者需要在try finally中调用ack方法，否则mq会一直等待unack消息的响应，除非消费者连接断开，mq会将unack的消息重新入队列。
    
3. broker本身通过队列/消息持久化。
    但是刷盘有延迟时间，因此磁盘故障仍然可能引起数据丢失。普通的rabbitMQ集群能够提高MQ的吞吐量，但是无法做到高可用。通过镜像队列做到队列的高可用，避免单点故障！通过HA进行负载均衡！通过KeepAlived对HA做高可用。

# 实现RPC
MQ本身是异步的消息处理，生产者发送完消息后不需要等待处理结果，不会关心处理成功或者失败。但是如果需要同步等待服务端将消息处理完后再进行下一步处理，相当于RPC同步调用。
客户端发送消息时，在消息的头部添加两个属性，replyTo(回调队列)表示告诉消费者处理完成之后将回调通知的消息发送到这个queue中，correlationId表示此次请求的标识号，回调消息中包含了这个标识，生产者能够根据这个id了解哪一条请求被成功或者失败执行了。
消费者收到消息后，需要生成一条应答消息发送到replyTo指向的queue，同时带上correlationId属性。

# 交换器无法根据自身的类型和路由键找到一个符合条件 的队列
当 mandatory 参数设为 true 时，交换器无法根据自身的类型和路由键找到一个符合条件 的队列，那么 RabbitMQ 会调用 Basic.Return 命令将消息返回给生产者。当 mandatory 参 数设置为 false 时，出现上述情形，则消息直接被丢弃

# rabbitMQ对过期消息处理？
如果队列和消息都设置了TTL，则以较小的为准。
1. 设置队列 TTL 属性的方法，一旦消息过期，就会从队列中抹去，队列中己过期的消息肯定在队 列头部，RabbitMQ 只要定期从队头开始扫描是否有过期的消息即可，
2. 消息本身进行单独设置，即使消息过期，也不会马上从队列中抹去，因为每条消息是否过期是在即将投递到消费者之前判定的。每条消息的过期时间不同，如果要删除所有过期消息势必要扫描整个队列，所以不如等到此消息即将 被消费时再判定是否过期， 如果过期再进行删除即可。

在 RabbitMQ 重启后，持久化的队列的过期时间会被重新计算。

# MQ顺序处理消息
[顺序保证](https://hacpai.com/article/1542162310805)
乱序的原因：
RabbitMQ：一个queue，多个consumer，或者一个consumer，并发进行消费；
Kafka：一个topic，一个partition，一个consumer，内部多线程或者多partion
如何保证顺序：
RabbitMQ：将原来的一个queue按照消息唯一标识分发到多个queue中，每个queue只有一个consumer，在consumer内部用内存队列排队，分发给底层不同的worker处理；
Kafka：kafka能够保证一个partition中数据消费是有序的，因此需要一个topic，一个partition，一个consumer，内部单线程消费；消息需要指定一个key，比如某个订单id，将订单相关的数据全部分发到一个partition中。

或者每个消息带有标识，消费者拿到消息后检查其依赖的标识是否被处理，如果没有则阻塞等待；或者都先落库，然后新起一个任务按照顺序执行数据库中数据。

# rocketmq事务
# rabbitmq集群架构，高可用，镜像队列？
# rabbitmq实现rpc？reply to回调队列作用？
https://my.oschina.net/u/3967312/blog/2252996

# rabbitmq流控机制？
当rabbitMQ的内存或者磁盘资源达到阈值后，会触发流控机制，阻塞生产者的Connection，让生产者不能继续发送消息，直至内存或者磁盘资源得到释放。
所以生产者最好采用异步发送数据，防止流控时阻塞业务主流程。（生产者可以获取流控引起的阻塞的事件，然后再做异步处理）

# 在单 node 系统和多 node 构成的 cluster 系统中声明 queue、exchange ，以及进行 binding 会有什么不同？
当你在单 node 上声明 queue 时，只要该 node 上相关元数据进行了变更，你就会得到 Queue.Declare-ok 回应；而在 cluster 上声明 queue ，则要求 cluster 上的全部 node 都要进行元数据成功更新，才会得到 Queue.Declare-ok 回应。另外，若 node 类型为 RAM node 则变更的数据仅保存在内存中，若类型为 disk node 则还要变更保存在磁盘上的数据。

# 若 cluster 中拥有某个 queue 的 owner node 失效了，且该 queue 被声明具有 durable 属性，是否能够成功从其他 node 上重新声明该 queue ？
不能，在这种情况下，将得到 404 NOT_FOUND 错误。只能等 queue 所属的 node 恢复后才能使用该 queue 。但若该 queue 本身不具有 durable 属性，则可在其他 node 上重新声明。

# 能够在地理上分开的不同数据中心使用 RabbitMQ cluster 么？
不能。第一，你无法控制所创建的 queue 实际分布在 cluster 里的哪个 node 上（一般使用 HAProxy + cluster 模型时都是这样），这可能会导致各种跨地域访问时的常见问题；第二，Erlang 的 OTP 通信框架对延迟的容忍度有限，这可能会触发各种超时，导致业务疲于处理；第三，在广域网上的连接失效问题将导致经典的“脑裂”问题，而 RabbitMQ 目前无法处理（该问题主要是说 Mnesia）

# 消息体大小
根据 AMQP 协议规定，消息体的大小由 64-bit 的值来指定，所以你就可以知道到底能发多大的数据了。

# Consumer Cancellation Notification 机制用于什么场景？
用于保证当镜像 queue 中 master 挂掉时，连接到 slave 上的 consumer 可以收到自身 consume 被取消的通知，进而可以重新执行 consume 动作从新选出的 master 出获得消息。若不采用该机制，连接到 slave 上的 consumer 将不会感知 master 挂掉这个事情，导致后续无法再收到新 master 广播出来的 message 。另外，因为在镜像 queue 模式下，存在将 message 进行 requeue 的可能，所以实现 consumer 的逻辑时需要能够正确处理出现重复 message 的情况。

# 消息如何发送
[面试问题](https://zhuanlan.zhihu.com/p/62087283)
首先客户端必须连接到 RabbitMQ 服务器才能发布和消费消息，客户端和 rabbit server 之间会创建一个 tcp 连接，一旦 tcp 打开并通过了认证（认证就是你发送给 rabbit 服务器的用户名和密码），你的客户端和 RabbitMQ 就创建了一条 amqp 信道（channel），信道是创建在“真实” tcp 上的虚拟连接，amqp 命令都是通过信道发送出去的，每个信道都会有一个唯一的 id，不论是发布消息，订阅队列都是通过这个信道完成的。


